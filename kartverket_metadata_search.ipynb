{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata VDB Search\n",
    "We will use Milvus and Towhee to help searches. Towhee is used to extract the semantics of the text and return the text embedding. The Milvus vector database can store and search vectors, and return related dataset's metadata. So we first need to install [Milvus](https://github.com/milvus-io/milvus) and [Towhee](https://github.com/towhee-io/towhee).\n",
    "\n",
    "Before getting started, please make sure that you have started a [Milvus service](https://milvus.io/docs/install_standalone-docker.md). This notebook uses [milvus 2.2.10](https://milvus.io/docs/v2.2.x/install_standalone-docker.md) and [pymilvus 2.2.11](https://milvus.io/docs/release_notes.md#2210).\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "`Things to look into:`\n",
    "1. Are there better encoding models for Norwegian text than 'facebook/dpr-ctx_encoder-single-nq-base'?\n",
    "2. What alternatives are there to RAG for search?\n",
    "3. What working alternatives have already been made by others (don't reinvent the wheel)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --upgrade pip\n",
    "#! pip3 install -q towhee pymilvus==2.2.11\n",
    "#! pip3 uninstall pymilvus -y\n",
    "\n",
    "! pip3 install -q towhee pymilvus==2.1.1\n",
    "! pip3 show pymilvus | grep -Ei 'Name:|Version:'\n",
    "! pip3 show towhee | grep -Ei 'Name:|Version:'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Adding embeddings for columns\n",
    "\n",
    "The dataset is from the [Kartverket dataset metadata](https://cdn.discordapp.com/attachments/1204433663035449384/1206537816654356480/metadata_no_format.csv?ex=65dc5ee7&is=65c9e9e7&hm=3b9a88db41103ef5393294c5eaeebb60ee2229f43724cc014d4cffc92de1f384&), which contains metadata about each dataset.\n",
    "\n",
    "The strings in the columns need to be converted to vector representations (embedding) using Towhee [text_embedding.dpr operator](https://towhee.io/text-embedding/dpr). Columns containing these new embedings should contain the original column name with `_vector` at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load dataset and vectorise chosen column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from towhee import pipe, ops, DataCollection\n",
    "\n",
    "\n",
    "# Function to compute embeddings for a single text\n",
    "def compute_embeddings(text):\n",
    "    MAX_TOKENS = 1000#512 # Temporary limit on number characters to convert\n",
    "    truncated_text = text[:MAX_TOKENS]\n",
    "    return DataCollection(embeddings_pipe(truncated_text)).to_list()[0]['vec']\n",
    "\n",
    "\n",
    "# Loads dataset into dataframe and recasts columns into correct datatypes\n",
    "df_kartverket = pd.read_excel('Metadata_excel.xlsx')\n",
    "recast_to_string = ['datasetcreationdate', 'metadatacreationdate']\n",
    "df_kartverket[recast_to_string] = df_kartverket[recast_to_string].astype('object')\n",
    "\n",
    "# Fill NaN values with an empty string\n",
    "df_kartverket.fillna('', inplace=True)\n",
    "\n",
    "# Pipe converting text to embeddings (vectors)\n",
    "# bert-base-multilingual-cased\n",
    "embeddings_pipe = (\n",
    "    pipe.input('text')\n",
    "        .map('text', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))\n",
    "        .output('vec')\n",
    ")\n",
    "\n",
    "# Process each column and create new columns for embeddings\n",
    "column_to_vectorise = 'abstract'\n",
    "df_kartverket[column_to_vectorise + '_vector'] = df_kartverket[column_to_vectorise].apply(compute_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of Milvus collection for metadata\n",
    "Before creating a collection. The database should be examined for existing collections, to avoid forever hanging collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPC error: [drop_collection], <MilvusException: (code=1, message=DescribeCollection failed: can't find collection: search_article_in_medium)>, <Time:{'RPC start': '2024-02-19 12:14:16.736174', 'RPC error': '2024-02-19 12:14:16.770256'}>\n",
      "RPC error: [drop_collection], <MilvusException: (code=1, message=DescribeCollection failed: can't find collection: your_collection_name)>, <Time:{'RPC start': '2024-02-19 12:14:16.771819', 'RPC error': '2024-02-19 12:14:16.825450'}>\n",
      "RPC error: [drop_collection], <MilvusException: (code=1, message=DescribeCollection failed: can't find collection: kartverket_metadata)>, <Time:{'RPC start': '2024-02-19 12:14:16.825981', 'RPC error': '2024-02-19 12:14:16.859923'}>\n",
      "RPC error: [drop_collection], <MilvusException: (code=1, message=DescribeCollection failed: can't find collection: search_article_in_medium_salesforce)>, <Time:{'RPC start': '2024-02-19 12:14:16.860577', 'RPC error': '2024-02-19 12:14:16.894352'}>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Could not drop collection: search_article_in_medium\n",
      "Could not drop collection: your_collection_name\n",
      "Could not drop collection: kartverket_metadata\n",
      "Could not drop collection: search_article_in_medium_salesforce\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import list_collections, drop_collection, connections, MilvusException\n",
    "\n",
    "server_host = 'ebjerk.no'\n",
    "server_port = '19530'\n",
    "\n",
    "connections.connect(host=server_host, port=server_port)\n",
    "print(list_collections())\n",
    "\n",
    "collections_to_drop = ['search_article_in_medium', 'your_collection_name', 'search_article_in_medium_salesforce']\n",
    "\n",
    "for collection in collections_to_drop:\n",
    "    try:\n",
    "        drop_collection(collection)\n",
    "    except MilvusException:\n",
    "        print(f'Could not drop collection: {collection}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of Milvus collection for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column_to_vectorise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     collection\u001b[38;5;241m.\u001b[39mcreate_index(field_name\u001b[38;5;241m=\u001b[39mvector_column, index_params\u001b[38;5;241m=\u001b[39mindex_params)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collection, collection_columns\n\u001b[0;32m---> 58\u001b[0m kartverket_collection, collection_columns \u001b[38;5;241m=\u001b[39m kartverket_create_milvus_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkartverket_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mcolumn_to_vectorise\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_vector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m768\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'column_to_vectorise' is not defined"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "\n",
    "connections.connect(host=server_host, port=server_port)\n",
    "\n",
    "def kartverket_create_milvus_collection(collection_name, vector_column, dim):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "\n",
    "    fields = [\n",
    "            FieldSchema(name='schema', dtype=DataType.VARCHAR, max_length=100),  \n",
    "            FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "            FieldSchema(name='uuid', dtype=DataType.VARCHAR, max_length=100), \n",
    "            FieldSchema(name='hierarchyLevel', dtype=DataType.VARCHAR, max_length=100),    \n",
    "            #FieldSchema(name='hierarchyLevel_vector', dtype=DataType.FLOAT_VECTOR, dim=dim), \n",
    "            FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=100),   \n",
    "            #FieldSchema(name=\"title_vector\", dtype=DataType.FLOAT_VECTOR, dim=dim),\n",
    "\n",
    "            FieldSchema(name='datasetcreationdate', dtype=DataType.VARCHAR, max_length=500),    \n",
    "            FieldSchema(name='abstract', dtype=DataType.VARCHAR, max_length=2000),   \n",
    "            FieldSchema(name='abstract_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='keyword', dtype=DataType.VARCHAR, max_length=2000),   \n",
    "            #FieldSchema(name='keyword_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='geoBox', dtype=DataType.VARCHAR, max_length=100),    \n",
    "            #FieldSchema(name='geoBox_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),    \n",
    "            FieldSchema(name='Constraints', dtype=DataType.VARCHAR, max_length=1000),   \n",
    "            #FieldSchema(name='Constraints_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "\n",
    "            FieldSchema(name='SecurityConstraints', dtype=DataType.VARCHAR, max_length=500),   \n",
    "            #FieldSchema(name='SecurityConstraints_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='LegalConstraints', dtype=DataType.VARCHAR, max_length=2000),   \n",
    "            #FieldSchema(name='LegalConstraints_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='temporalExtent', dtype=DataType.VARCHAR, max_length=100),    \n",
    "            ##FieldSchema(name='temporalExtent_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),    \n",
    "            FieldSchema(name='image', dtype=DataType.VARCHAR, max_length=1000),    \n",
    "            FieldSchema(name='responsibleParty', dtype=DataType.VARCHAR, max_length=500),   \n",
    "            #FieldSchema(name='responsibleParty_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "\n",
    "            FieldSchema(name='link', dtype=DataType.VARCHAR, max_length=500),    \n",
    "            #FieldSchema(name='metadatacreationdate', dtype=DataType.VARCHAR, max_length=500), # SUS field, encoding error?\n",
    "            ##FieldSchema(name='metadatacreationdate_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),    \n",
    "            FieldSchema(name='productInformation', dtype=DataType.VARCHAR, max_length=1000),   \n",
    "            #FieldSchema(name='productInformation_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='parentId', dtype=DataType.VARCHAR, max_length=100),   \n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='search text')\n",
    "    collection_columns = [field_schema.name for field_schema in schema.fields]\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "    \n",
    "    index_params = {\n",
    "        'metric_type': \"L2\",\n",
    "        'index_type': \"IVF_FLAT\",\n",
    "        'params': {\"nlist\": 2048}\n",
    "    }\n",
    "    collection.create_index(field_name=vector_column, index_params=index_params)\n",
    "    return collection, collection_columns\n",
    "\n",
    "kartverket_collection, collection_columns = kartverket_create_milvus_collection('kartverket_metadata', column_to_vectorise + '_vector', 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creation of dataframe subset to exclude columns with complex data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the correct columns from the dataframe in the correct order for milvus\n",
    "df_kartverket_slice = df_kartverket[collection_columns]\n",
    "df_kartverket_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Insert the subset dataframe data into Milvus collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from towhee import ops, pipe, DataCollection\n",
    "\n",
    "insert_pipe_kartverket = (pipe.input('df_kartverket_slice')\n",
    "                   .flat_map('df_kartverket_slice', 'data', lambda df: df.values.tolist())\n",
    "                   .map('data', 'res', ops.ann_insert.milvus_client(host=server_host, \n",
    "                                                                    port=server_port,\n",
    "                                                                    collection_name='kartverket_metadata'))\n",
    "                   .output('res')\n",
    ")\n",
    "\n",
    "%time _ = insert_pipe_kartverket(df_kartverket_slice)\n",
    "\n",
    "\n",
    "kartverket_collection.load()\n",
    "kartverket_collection.num_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare pipe that accepts queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Variables specifying what column and collection to perform ANN comparrison against\n",
    "vector_columns = [column_to_vectorise + '_vector']\n",
    "collection_name = 'kartverket_metadata'\n",
    "\n",
    "print(df_kartverket.columns)\n",
    "# What columns to return for view\n",
    "response_output = [\n",
    "       'id', 'id', 'title', # required to have two 'id'\n",
    "       'abstract', 'keyword', 'Constraints',\n",
    "       'SecurityConstraints', 'LegalConstraints',\n",
    "       'responsibleParty', 'productInformation', 'parentId'\n",
    "]\n",
    "\n",
    "\n",
    "demo_pipe = (pipe.input('query')\n",
    "                    .map('query', 'vec', ops.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\"))\n",
    "                    .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "                    .flat_map('vec', ('id', 'score', 'id', 'title', # required to have two 'id'\n",
    "                            'abstract', 'keyword', 'Constraints',\n",
    "                            'SecurityConstraints', 'LegalConstraints',\n",
    "                            'responsibleParty', 'productInformation', 'parentId'), \n",
    "                                       ops.ann_search.milvus_client(host=server_host, \n",
    "                                                                    port=server_port,\n",
    "                                                                    collection_name=collection_name,\n",
    "                                                                    vector_field=vector_columns,\n",
    "                                                                    output_fields=response_output, \n",
    "                                                                    limit=5))  \n",
    "                    .output(*['query', 'score'], *response_output)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Query against metadata collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kartverket_question1 = 'Hvor er bomberom?'\n",
    "print(f'\\n\"{kartverket_question1}\" search:')\n",
    "res_kartverket1 = demo_pipe(kartverket_question1)\n",
    "DataCollection(res_kartverket1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Format response into GPT API request\n",
    "After the query is vectorised, and then compared against the database's vector column to find the most simmilar result(s). The most similar result's metadata can be formatted into a instruction with example for GPT. This way, we can instruct GPT how to answer the query by providing a demonstration. Before prompting with the query's current context, and the instruction to answer.\n",
    "\n",
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_demonstration = '''query\tscore\tid\tid\ttitle\tabstract\tkeyword\tConstraints\tSecurityConstraints\tLegalConstraints\tresponsibleParty\tproductInformation\tparentId\n",
    "Hvor er bomberom?\t118.3987045288086\t22788\t22788\tMagasin\tDatabase over regulerte innsjøer. Egenskapsdata er vassdragsnr., magasinnr., navn, laveste og høyeste regulerte vannstand (m.o.h...\tAnnet###Åpne data###Norge digitalt###modellbaserteVegprosjekter###fellesDatakatalog###Energi###Norge fastland###magasin###vannkr...\tBruksbegrensninger Ingen ###Ingen\tSikkerhetsnivå Ugradert: Available for general disclosure#########\tTilgangsrestriksjoner Andre restriksjoner: Limitation not listed######Andre restriksjonerÅpne data###Åpne data###Brukerrestriksj...\tSeming Haakon SkauNorges vassdrags- og energidirektoratgisstotte@nve.no###NVE - Seksjon for geomatikk og dataanalyse/IGDNorges v...\tProduktspesifikasjon###Produktark###Produktside###Tegnforklaring###dekningsoversikt###hjelp###dekningsoversikt rutenett###deknin...\n",
    "Hvor er bomberom?\t123.4372329711914\t21492\t21492\tBunnsedimenter (kornstørrelse), detaljert\tDatasettet viser kornstørrelsessammensetning i sjøbunnssedimentenes øvre del (øverste 0-10 cm av sjøbunnen). I egenskapstabellen...\tSea regions###Inspire###Norge digitalt###geodataloven###Mareano###ØkologiskGrunnkart###MarineGrunnkart###fellesDatakatalog###Geo...\tBruksbegrensninger Detaljnivået på datasettet tilsier bruk innenfor kartmålestokken: 1:20.000 - 1:150.000. ###Detaljnivået på d...\tSikkerhetsnivå Ugradert: Available for general disclosure#########\tTilgangsrestriksjoner Andre restriksjoner: Limitation not listed######Andre restriksjonerÅpne data###Åpne data###Brukerrestriksj...\tAave LeplandNorges geologiske undersøkelseDataadministrator4773904000Leiv Eirikssons vei 39TrondheimAave.Lepland@ngu.nohttp://ww...\thttps://register.geonorge.no/produktspesifikasjoner/bunnsedimenter-kornstørrelseProduktspesifikasjon###https://register.geonorge...\n",
    "Hvor er bomberom?\t124.96815490722656\t68030\t68030\tBunnsedimenter (kornstørrelse), oversikt\tDatasettet viser kornstørrelsessammensetning i sjøbunnssedimentenes øvre del. Kornstørrelsesdata er basert på analyser av sjøbun...\tSea regions###Inspire###Norge digitalt###geodataloven###Mareano###fellesDatakatalog###Geologi###Norge###Nordsjøen###Norskehavet#...\tBruksbegrensninger Detaljnivået på datasettet tilsier bruk innenfor kartmålestokken: 1:2000.000 - 1:10.000.000 ###Detaljnivået ...\tSikkerhetsnivå Ugradert: Available for general disclosure#########\tTilgangsrestriksjoner Andre restriksjoner: Limitation not listed######Andre restriksjonerÅpne data###Åpne data###Brukerrestriksj...\tAave LeplandNorges geologiske undersøkelseDataadministrator4773904000Leiv Eirikssons vei 39TrondheimAave.Lepland@ngu.nohttp://ww...\thttps://register.geonorge.no/produktspesifikasjoner/bunnsedimenter-kornstørrelseProduktspesifikasjon###https://register.geonorge...\n",
    "Hvor er bomberom?\t125.0992431640625\t75832\t75832\tVegetasjon - Naturtyper\tKommunvise kartlag i datasettet Vegetasjon som viser naturtyper som er viktig for biologisk mangfold og som helt eller delvis ka...\tLand cover###Åpne data###Norge digitalt###fellesDatakatalog###Landbruk###Natur###Norge fastland###Vegetasjon###Arealdekke###Vege...\tBruksbegrensninger Ingen ###Ingen\tSikkerhetsnivå Ugradert: Available for general disclosure#########\tTilgangsrestriksjoner Andre restriksjoner: Limitation not listed######Andre restriksjonerÅpne data###Åpne data###Brukerrestriksj...\tIngvild NystuenNorsk institutt for bioøkonomiSeksjonsleder64 94 80 0064 94 80 01Raveien 9ÅsAkersjusPostboks 115, 1430 ÅsNorgegis...\thttp://www.skogoglandskap.no/seksjoner/nedlastingsinformasjonNedlastingsinformasjon###http://www.skogoglandskap.no/kart/vegetasj...\n",
    "Hvor er bomberom?\t125.26884460449219\t69607\t69607\tRelativ bunnhardhet, åpne data\tRelativ bunnhardhet er rasterdata som viser reflektivitetstyrke fra sjøbunnen. Reflektivitetsstyrke sier noe om sjøbunnens akust...\tGeology###Åpne data###Norge digitalt###MarineGrunnkart###modellbaserteVegprosjekter###fellesDatakatalog###Geologi###Norge###Bare...\tBruksbegrensninger Ingen begrensninger på bruk er oppgitt. ###Ingen begrensninger på bruk er oppgitt.No conditions apply\tSikkerhetsnivå Ugradert: Available for general disclosure#########\tTilgangsrestriksjoner Andre restriksjoner: Limitation not listed######Andre restriksjonerÅpne data###Åpne data###Brukerrestriksj...\tAave LeplandNorges geologiske undersøkelseDataadministrator, Maringeologi, NGU4773904000Leiv Eirikssons vei 39TrondheimAave.Lepl...\tProduktspesifikasjon###https://register.geonorge.no/register/versjoner/produktark/norges-geologiske-undersokelse/relativ-bunnhar...'''\n",
    "metadata_link = 'https://ipt.nina.no/'\n",
    "\n",
    "query = f'Finn dataset med magasin'\n",
    "instruction_gpt = f'Skriv en respons som finner det mest korresponderende datasettet fra metadata for spørringen:'\n",
    "demonstration = f'Spørring: Hvor er bomberom?\\nMetadata: {metadata_demonstration}\\nRespons: Ut i fra spørringen ser det ut som at du leter etter datasettet Tilfluktsrom (nedlastningslink: {metadata_link}). Dette datsettet inneholder informasjon om lokasjonene til alle offentlige tilfluktsrom (bomberom) i Norge'\n",
    "current_query_instruction = f'Spørring:{query}\\nMetadata: {metadata_demonstration}\\nRespons:'\n",
    "API_text = f'{instruction_gpt}\\n{demonstration}\\n\\n{current_query_instruction}'\n",
    "print(API_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
