{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata VDB Search\n",
    "We will use Milvus and Towhee to help searches. Towhee is used to extract the semantics of the text and return the text embedding. The Milvus vector database can store and search vectors, and return related dataset's metadata. So we first need to install [Milvus](https://github.com/milvus-io/milvus) and [Towhee](https://github.com/towhee-io/towhee).\n",
    "\n",
    "Before getting started, please make sure that you have started a [Milvus service](https://milvus.io/docs/install_standalone-docker.md). This notebook uses [milvus 2.2.10](https://milvus.io/docs/v2.2.x/install_standalone-docker.md) and [pymilvus 2.2.11](https://milvus.io/docs/release_notes.md#2210)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --upgrade pip\n",
    "#! pip3 install -q towhee pymilvus==2.2.11\n",
    "#! pip3 uninstall pymilvus -y\n",
    "\n",
    "! pip3 install -q towhee pymilvus==2.1.1\n",
    "! pip3 show pymilvus | grep -Ei 'Name:|Version:'\n",
    "! pip3 show towhee | grep -Ei 'Name:|Version:'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Adding embeddings for columns\n",
    "\n",
    "The dataset is from the [Kartverket dataset metadata](https://cdn.discordapp.com/attachments/1204433663035449384/1206537816654356480/metadata_no_format.csv?ex=65dc5ee7&is=65c9e9e7&hm=3b9a88db41103ef5393294c5eaeebb60ee2229f43724cc014d4cffc92de1f384&), which contains metadata about each dataset.\n",
    "\n",
    "The strings in the columns need to be converted to vector representations (embedding) using Towhee [text_embedding.dpr operator](https://towhee.io/text-embedding/dpr). Columns containing these new embedings should contain the original column name with `_vector` at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB In case pandas cannot read the csv, due to a delimiter parsing error\n",
    "\n",
    "Use the code below to reformat the delimiters to \"|\", `NB! Also replace the excess ones inside sentences that replaced the regular commas.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for reformatting the delimiters to \"|\"\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def replace_delimiter(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Regular expression to match commas not inside double quotes\n",
    "    pattern = r',(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)'\n",
    "\n",
    "    # Replace the matched commas with '|'\n",
    "    new_content = re.sub(pattern, '|', content)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(new_content)\n",
    "\n",
    "# Replace this with your actual file paths\n",
    "input_file = 'metadata.csv'\n",
    "output_file = 'output_metadata_modified.csv'\n",
    "\n",
    "replace_delimiter(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load dataset and vectorise chosen column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from towhee import pipe, ops, DataCollection\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Function to compute embeddings for a single text\n",
    "def compute_embeddings(text):\n",
    "    MAX_TOKENS = 512 # Temporary limit on number characters to convert\n",
    "    truncated_text = text[:MAX_TOKENS]\n",
    "    return DataCollection(embeddings_pipe(truncated_text)).to_list()[0]['vec']\n",
    "\n",
    "\n",
    "# Loads dataset into dataframe and recasts columns into correct datatypes\n",
    "df_kartverket = pd.read_excel('Metadata_excel.xlsx')\n",
    "recast_to_string = ['datasetcreationdate', 'metadatacreationdate']\n",
    "df_kartverket[recast_to_string] = df_kartverket[recast_to_string].astype('object')\n",
    "\n",
    "# Fill NaN values with an empty string\n",
    "df_kartverket.fillna('', inplace=True)\n",
    "\n",
    "# Pipe converting text to embeddings (vectors)\n",
    "embeddings_pipe = (\n",
    "    pipe.input('text')\n",
    "        .map('text', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))\n",
    "        .output('vec')\n",
    ")\n",
    "\n",
    "# Process each column and create new columns for embeddings\n",
    "column_to_vectorise = 'title'\n",
    "df_kartverket[column_to_vectorise + '_vector'] = df_kartverket[column_to_vectorise].apply(compute_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from towhee import pipe, ops\n",
    "\n",
    "def insert_data_to_milvus_with_towhee(df, server_host, server_port, collection_name):\n",
    "    try:\n",
    "        # Define the pipeline\n",
    "        insert_pipe = (pipe.input('data_frame')\n",
    "                       .flat_map('data_frame', 'data', lambda df: df.values.tolist())\n",
    "                       .map('data', 'res', ops.ann_insert.milvus_client(host=server_host, \n",
    "                                                                        port=server_port,\n",
    "                                                                        collection_name=collection_name))\n",
    "                       .output('res'))\n",
    "\n",
    "        # Execute the pipeline\n",
    "        results = insert_pipe(df)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during insertion: {e}\")\n",
    "\n",
    "# Usage\n",
    "server_host = 'ebjerk.no'\n",
    "server_port = '19530'\n",
    "collection_name = 'kartverket_metadata'\n",
    "\n",
    "inserted_ids = insert_data_to_milvus_with_towhee(df_kartverket, server_host, server_port, collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of Milvus collection for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "server_host = 'ebjerk.no'\n",
    "server_port = '19530'\n",
    "\n",
    "connections.connect(host=server_host, port=server_port)\n",
    "\n",
    "def kartverket_create_milvus_collection(collection_name, dim):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "\n",
    "    fields = [\n",
    "            #FieldSchema(name='schema', dtype=DataType.STRING, max_length=100), # REQUIRES STRING TYPE \n",
    "            FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "            #FieldSchema(name='uuid', dtype=DataType.VARCHAR, max_length=100), # REQUIRES STRING TYPE\n",
    "            #FieldSchema(name='hierarchyLevel', dtype=DataType.VARCHAR, max_length=100), # REQUIRES STRING TYPE   \n",
    "            #FieldSchema(name='hierarchyLevel_vector', dtype=DataType.FLOAT_VECTOR, dim=dim), #REQUIRES STRING TYPE   \n",
    "            FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=100),   \n",
    "            FieldSchema(name=\"title_vector\", dtype=DataType.FLOAT_VECTOR, dim=dim),\n",
    "\n",
    "            #FieldSchema(name='datasetcreationdate', dtype=DataType.VARCHAR, max_length=500), # REQUIRES STRING TYPE   \n",
    "            FieldSchema(name='abstract', dtype=DataType.VARCHAR, max_length=2000),   \n",
    "            #FieldSchema(name='abstract_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='keyword', dtype=DataType.VARCHAR, max_length=2000),   \n",
    "            #FieldSchema(name='keyword_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            #FieldSchema(name='geoBox', dtype=DataType.VARCHAR, max_length=100), # REQUIRES STRING TYPE   \n",
    "            #FieldSchema(name='geoBox_vector', dtype=DataType.FLOAT_VECTOR, dim=dim), # REQUIRES STRING TYPE   \n",
    "            FieldSchema(name='Constraints', dtype=DataType.VARCHAR, max_length=1000),   \n",
    "            #FieldSchema(name='Constraints_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "\n",
    "            FieldSchema(name='SecurityConstraints', dtype=DataType.VARCHAR, max_length=500),   \n",
    "            #FieldSchema(name='SecurityConstraints_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='LegalConstraints', dtype=DataType.VARCHAR, max_length=2000),   \n",
    "            #FieldSchema(name='LegalConstraints_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            #FieldSchema(name='temporalExtent', dtype=DataType.VARCHAR, max_length=100), # REQUIRES STRING TYPE   \n",
    "            ##FieldSchema(name='temporalExtent_vector', dtype=DataType.FLOAT_VECTOR, dim=dim), # REQUIRES STRING TYPE   \n",
    "            #FieldSchema(name='image', dtype=DataType.VARCHAR, max_length=1000), # REQUIRES STRING TYPE   \n",
    "            FieldSchema(name='responsibleParty', dtype=DataType.VARCHAR, max_length=500),   \n",
    "            #FieldSchema(name='responsibleParty_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "\n",
    "            #FieldSchema(name='link', dtype=DataType.VARCHAR, max_length=500), # REQUIRES STRING TYPE   \n",
    "            #FieldSchema(name='metadatacreationdate', dtype=DataType.VARCHAR, max_length=500), # REQUIRES STRING TYPE   \n",
    "            ##FieldSchema(name='metadatacreationdate_vector', dtype=DataType.FLOAT_VECTOR, dim=dim), # REQUIRES STRING TYPE   \n",
    "            FieldSchema(name='productInformation', dtype=DataType.VARCHAR, max_length=1000),   \n",
    "            #FieldSchema(name='productInformation_vector', dtype=DataType.FLOAT_VECTOR, dim=dim),   \n",
    "            FieldSchema(name='parentId', dtype=DataType.VARCHAR, max_length=100),   \n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='search text')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "    \n",
    "    index_params = {\n",
    "        'metric_type': \"L2\",\n",
    "        'index_type': \"IVF_FLAT\",\n",
    "        'params': {\"nlist\": 2048}\n",
    "    }\n",
    "    collection.create_index(field_name='title_vector', index_params=index_params)\n",
    "    return collection\n",
    "\n",
    "kartverket_collection = kartverket_create_milvus_collection('kartverket_metadata', 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creation of dataframe subset to exclude columns with complex data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kartverket_slice = df_kartverket[['id', 'title', 'title_vector', 'abstract', 'keyword', 'Constraints', 'SecurityConstraints', 'LegalConstraints', 'responsibleParty', 'productInformation', 'parentId']]\n",
    "df_kartverket_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Insert the subset dataframe data into Milvus collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from towhee import ops, pipe, DataCollection\n",
    "\n",
    "insert_pipe_kartverket = (pipe.input('df_kartverket_slice')\n",
    "                   .flat_map('df_kartverket_slice', 'data', lambda df: df.values.tolist())\n",
    "                   .map('data', 'res', ops.ann_insert.milvus_client(host=server_host, \n",
    "                                                                    port=server_port,\n",
    "                                                                    collection_name='kartverket_metadata'))\n",
    "                   .output('res')\n",
    ")\n",
    "\n",
    "%time _ = insert_pipe_kartverket(df_kartverket_slice)\n",
    "\n",
    "\n",
    "kartverket_collection.load()\n",
    "kartverket_collection.num_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query against metadata collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Variables specifying what column and collection to perform ANN comparrison against\n",
    "vector_columns = ['title_vector']\n",
    "collection_name = 'kartverket_metadata'\n",
    "\n",
    "print(df_kartverket.columns)\n",
    "# What columns to return for view\n",
    "response_output = [\n",
    "       'id', 'title',\n",
    "       'abstract', 'keyword', 'Constraints',\n",
    "       'SecurityConstraints', 'LegalConstraints',\n",
    "       'responsibleParty', 'productInformation', 'parentId'\n",
    "]\n",
    "\n",
    "\n",
    "demo_pipe = (pipe.input('query')\n",
    "                    .map('query', 'vec', ops.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\"))\n",
    "                    .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "                    .flat_map('vec', ('id', 'score', 'title',\n",
    "       'abstract', 'keyword', 'Constraints',\n",
    "       'SecurityConstraints', 'LegalConstraints',\n",
    "       'responsibleParty', 'productInformation', 'parentId'), \n",
    "                                       ops.ann_search.milvus_client(host=server_host, \n",
    "                                                                    port=server_port,\n",
    "                                                                    collection_name=collection_name,\n",
    "                                                                    vector_field=vector_columns,\n",
    "                                                                    output_fields=response_output, \n",
    "                                                                    limit=5))  \n",
    "                    .output(*['query', 'score'], *response_output)\n",
    "               )\n",
    "\n",
    "kartverket_question1 = 'Just do it'\n",
    "print(f'\\n\"{kartverket_question1}\" search:')\n",
    "res_kartverket1 = demo_pipe(kartverket_question1)\n",
    "DataCollection(res_kartverket1).show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
