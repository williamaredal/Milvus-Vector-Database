{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pymilvus\n",
      "Version: 2.1.1\n",
      "Name: towhee\n",
      "Version: 1.1.3\n"
     ]
    }
   ],
   "source": [
    "#! pip install --upgrade pip\n",
    "#! pip3 install -q towhee pymilvus==2.2.11\n",
    "#! pip3 uninstall pymilvus -y\n",
    "\n",
    "! pip3 install -q towhee pymilvus==2.1.1\n",
    "! pip3 install transformers -q\n",
    "! pip3 install pandas -q\n",
    "! pip3 install tqdm -q\n",
    "! pip3 show pymilvus | grep -Ei 'Name:|Version:'\n",
    "! pip3 show towhee | grep -Ei 'Name:|Version:'\n",
    "#! pip3 show transformers | grep -Ei 'Name:|Version:'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Clean dataset for special characters, and output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema</th>\n",
       "      <th>uuid</th>\n",
       "      <th>id</th>\n",
       "      <th>hierarchyLevel</th>\n",
       "      <th>title</th>\n",
       "      <th>datasetcreationdate</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keyword</th>\n",
       "      <th>geoBox</th>\n",
       "      <th>Constraints</th>\n",
       "      <th>SecurityConstraints</th>\n",
       "      <th>LegalConstraints</th>\n",
       "      <th>temporalExtent</th>\n",
       "      <th>image</th>\n",
       "      <th>responsibleParty</th>\n",
       "      <th>link</th>\n",
       "      <th>metadatacreationdate</th>\n",
       "      <th>productInformation</th>\n",
       "      <th>parentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iso19139</td>\n",
       "      <td>7a62f16f-9aeb-4c39-bf5f-e710232fa366</td>\n",
       "      <td>37228</td>\n",
       "      <td>software</td>\n",
       "      <td>Artsfunn</td>\n",
       "      <td></td>\n",
       "      <td>Datasettet inneholder stedfestet informasjon a...</td>\n",
       "      <td>Natur,Norge,Svalbard,lav,karplanter,botanikkda...</td>\n",
       "      <td>2,33,57,81</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tilgangsrestriksjoner Andre restriksjoner: Lim...</td>\n",
       "      <td>0001-01-01now</td>\n",
       "      <td>https://editor.geonorge.no/thumbnails/7a62f16f...</td>\n",
       "      <td>Frank HansenNorsk institutt for naturforskning...</td>\n",
       "      <td>https://ipt.nina.no/</td>\n",
       "      <td>2021-03-24</td>\n",
       "      <td>Produktspesifikasjon,Produktark,Produktside,Te...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iso19139</td>\n",
       "      <td>79013154-92ee-4647-b160-925cbc148601</td>\n",
       "      <td>21400</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Hav og is - Iskart (shapefil)</td>\n",
       "      <td></td>\n",
       "      <td>Istjenesten ved Meteorologisk institutt utarbe...</td>\n",
       "      <td>Oceanographic geographical features,Inspire,No...</td>\n",
       "      <td>2.00,33.00,57.00,72.00</td>\n",
       "      <td>Bruksbegrensninger Ingen begrensninger på bruk...</td>\n",
       "      <td>Sikkerhetsnivå Ugradert: Available for general...</td>\n",
       "      <td>Tilgangsrestriksjoner Andre restriksjoner: Lim...</td>\n",
       "      <td>0001-01-01now</td>\n",
       "      <td>https://www.geonorge.no/geonetwork/srv/nor/res...</td>\n",
       "      <td>Meteorologisk instituttistjenesten@met.no,Mete...</td>\n",
       "      <td>http://polarview.met.no/</td>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>Produktspesifikasjon,Produktark,Produktside,Te...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iso19139</td>\n",
       "      <td>f0083871-0d21-44e2-945f-9de9ea94d484</td>\n",
       "      <td>240</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Losbordingsfelt</td>\n",
       "      <td></td>\n",
       "      <td>Bordingsfelt er angitt som et geografisk punkt...</td>\n",
       "      <td>Åpne data,Norge digitalt,modellbaserteVegprosj...</td>\n",
       "      <td>2.3987,33.2045,57.5765,71.3531</td>\n",
       "      <td></td>\n",
       "      <td>Sikkerhetsnivå Ugradert: Available for general...</td>\n",
       "      <td>Tilgangsrestriksjoner Andre restriksjoner: Lim...</td>\n",
       "      <td>0001-01-01now</td>\n",
       "      <td>https://editor.geonorge.no/thumbnails/f0083871...</td>\n",
       "      <td>Stian AamotKystverket37019700Kystveien 30Arend...</td>\n",
       "      <td>javascript:addWMSServerLayers(\\https://kystinf...</td>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>https://register.geonorge.no/register/versjone...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iso19139</td>\n",
       "      <td>e379ef5e-8851-4305-b900-44a4587cf14c</td>\n",
       "      <td>21273</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Radnett - doseratemålestasjoner</td>\n",
       "      <td></td>\n",
       "      <td>Datasettet inneholder strålevernets radnettsta...</td>\n",
       "      <td>Norge digitalt,Åpne data,modellbaserteVegprosj...</td>\n",
       "      <td>2,33,57.00000000000001,72</td>\n",
       "      <td>Bruksbegrensninger Ingen begrensninger på bruk...</td>\n",
       "      <td>Sikkerhetsnivå Ugradert: Available for general...</td>\n",
       "      <td>Tilgangsrestriksjoner Andre restriksjoner: Lim...</td>\n",
       "      <td>0001-01-01now</td>\n",
       "      <td>https://editor.geonorge.no/thumbnails/e379ef5e...</td>\n",
       "      <td>Statens strålevernnrpa@nrpa.no,Direktoratet fo...</td>\n",
       "      <td>https://radnett.dsa.no/index.html</td>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>Produktspesifikasjon,Produktark,Produktside,Te...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iso19139</td>\n",
       "      <td>41ccca92-2ae9-43c9-9a45-b3d6424d1633</td>\n",
       "      <td>37251</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Predikert utbredelse og tetthetsfordeling av s...</td>\n",
       "      <td></td>\n",
       "      <td>Basert på gamle og nye data for forekomst av s...</td>\n",
       "      <td>Species distribution,Norge digitalt,modellbase...</td>\n",
       "      <td>2,33,57,81</td>\n",
       "      <td>Bruksbegrensninger Ingen ,IngenNo conditions a...</td>\n",
       "      <td>Sikkerhetsnivå Ugradert: Available for general...</td>\n",
       "      <td>Tilgangsrestriksjoner Andre restriksjoner: Lim...</td>\n",
       "      <td>0001-01-01now</td>\n",
       "      <td>https://www.geonorge.no/geonetwork/srv/nor/res...</td>\n",
       "      <td>Norsk institutt for naturforskningfrank.hansse...</td>\n",
       "      <td>http://www.seapop.no/no/spread/open-sea/specie...</td>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>Produktspesifikasjon,Produktark,Produktside,Te...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     schema                                  uuid     id hierarchyLevel  \\\n",
       "0  iso19139  7a62f16f-9aeb-4c39-bf5f-e710232fa366  37228       software   \n",
       "1  iso19139  79013154-92ee-4647-b160-925cbc148601  21400        dataset   \n",
       "2  iso19139  f0083871-0d21-44e2-945f-9de9ea94d484    240        dataset   \n",
       "3  iso19139  e379ef5e-8851-4305-b900-44a4587cf14c  21273        dataset   \n",
       "4  iso19139  41ccca92-2ae9-43c9-9a45-b3d6424d1633  37251        dataset   \n",
       "\n",
       "                                               title datasetcreationdate  \\\n",
       "0                                           Artsfunn                       \n",
       "1                      Hav og is - Iskart (shapefil)                       \n",
       "2                                    Losbordingsfelt                       \n",
       "3                    Radnett - doseratemålestasjoner                       \n",
       "4  Predikert utbredelse og tetthetsfordeling av s...                       \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Datasettet inneholder stedfestet informasjon a...   \n",
       "1  Istjenesten ved Meteorologisk institutt utarbe...   \n",
       "2  Bordingsfelt er angitt som et geografisk punkt...   \n",
       "3  Datasettet inneholder strålevernets radnettsta...   \n",
       "4  Basert på gamle og nye data for forekomst av s...   \n",
       "\n",
       "                                             keyword  \\\n",
       "0  Natur,Norge,Svalbard,lav,karplanter,botanikkda...   \n",
       "1  Oceanographic geographical features,Inspire,No...   \n",
       "2  Åpne data,Norge digitalt,modellbaserteVegprosj...   \n",
       "3  Norge digitalt,Åpne data,modellbaserteVegprosj...   \n",
       "4  Species distribution,Norge digitalt,modellbase...   \n",
       "\n",
       "                           geoBox  \\\n",
       "0                      2,33,57,81   \n",
       "1          2.00,33.00,57.00,72.00   \n",
       "2  2.3987,33.2045,57.5765,71.3531   \n",
       "3       2,33,57.00000000000001,72   \n",
       "4                      2,33,57,81   \n",
       "\n",
       "                                         Constraints  \\\n",
       "0                                                      \n",
       "1  Bruksbegrensninger Ingen begrensninger på bruk...   \n",
       "2                                                      \n",
       "3  Bruksbegrensninger Ingen begrensninger på bruk...   \n",
       "4  Bruksbegrensninger Ingen ,IngenNo conditions a...   \n",
       "\n",
       "                                 SecurityConstraints  \\\n",
       "0                                                      \n",
       "1  Sikkerhetsnivå Ugradert: Available for general...   \n",
       "2  Sikkerhetsnivå Ugradert: Available for general...   \n",
       "3  Sikkerhetsnivå Ugradert: Available for general...   \n",
       "4  Sikkerhetsnivå Ugradert: Available for general...   \n",
       "\n",
       "                                    LegalConstraints temporalExtent  \\\n",
       "0  Tilgangsrestriksjoner Andre restriksjoner: Lim...  0001-01-01now   \n",
       "1  Tilgangsrestriksjoner Andre restriksjoner: Lim...  0001-01-01now   \n",
       "2  Tilgangsrestriksjoner Andre restriksjoner: Lim...  0001-01-01now   \n",
       "3  Tilgangsrestriksjoner Andre restriksjoner: Lim...  0001-01-01now   \n",
       "4  Tilgangsrestriksjoner Andre restriksjoner: Lim...  0001-01-01now   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://editor.geonorge.no/thumbnails/7a62f16f...   \n",
       "1  https://www.geonorge.no/geonetwork/srv/nor/res...   \n",
       "2  https://editor.geonorge.no/thumbnails/f0083871...   \n",
       "3  https://editor.geonorge.no/thumbnails/e379ef5e...   \n",
       "4  https://www.geonorge.no/geonetwork/srv/nor/res...   \n",
       "\n",
       "                                    responsibleParty  \\\n",
       "0  Frank HansenNorsk institutt for naturforskning...   \n",
       "1  Meteorologisk instituttistjenesten@met.no,Mete...   \n",
       "2  Stian AamotKystverket37019700Kystveien 30Arend...   \n",
       "3  Statens strålevernnrpa@nrpa.no,Direktoratet fo...   \n",
       "4  Norsk institutt for naturforskningfrank.hansse...   \n",
       "\n",
       "                                                link metadatacreationdate  \\\n",
       "0                               https://ipt.nina.no/           2021-03-24   \n",
       "1                           http://polarview.met.no/           2023-11-15   \n",
       "2  javascript:addWMSServerLayers(\\https://kystinf...           2023-11-15   \n",
       "3                  https://radnett.dsa.no/index.html           2023-11-15   \n",
       "4  http://www.seapop.no/no/spread/open-sea/specie...           2023-11-15   \n",
       "\n",
       "                                  productInformation parentId  \n",
       "0  Produktspesifikasjon,Produktark,Produktside,Te...           \n",
       "1  Produktspesifikasjon,Produktark,Produktside,Te...           \n",
       "2  https://register.geonorge.no/register/versjone...           \n",
       "3  Produktspesifikasjon,Produktark,Produktside,Te...           \n",
       "4  Produktspesifikasjon,Produktark,Produktside,Te...           "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Clean the 'abstract' column for weird substrings\n",
    "def clean_abstract(text):\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "\n",
    "    text = text.replace('\"', '').replace('\\\\', '')\n",
    "\n",
    "    # Pattern to match substrings starting with '(', containing chars, followed by 'http', and ending with ')', or that start and ending with commas, that also containins 'http'\n",
    "    link_pattern_xor = r'\\([^)]*http[^)]*\\)|,([^,]*http[^,]*),'\n",
    "    isolated_link_pattern = r'https?://\\S+(?=\\s|$)'\n",
    "    # Regex pattern for replacing trailing spaces with a single space\n",
    "    trailing_space_pattern = r' {2,}'\n",
    "\n",
    "    # Removes links within parentheses and commas, then replaces trailing spaces with single space\n",
    "    text = re.sub(trailing_space_pattern, ' ', re.sub(isolated_link_pattern, '', re.sub(link_pattern_xor, '', text)))\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# Replaces special characters on text columns\n",
    "def clean_special_substrings(text):\n",
    "    # Removes special characters and weird substrings\n",
    "    text = text.replace(' v/ ', ' ').replace('\\\\n', ' ').replace('▬', '').replace('\\u00A0', ' ')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_hash_delimiter(text):\n",
    "    text = text.replace('###', ',')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_constraints_column(text):\n",
    "    if text == '###':\n",
    "        text = text.replace('###', '')\n",
    "    else:\n",
    "        text = text.replace('###', ',')\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_security_constraints(text):\n",
    "    text = text.replace('#########', '').replace('######', ',').replace('###', ',')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_legal_constraints(text):\n",
    "    text = text.replace('######', ',').replace('###', ',')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_contact(text):\n",
    "    text = text.replace('###', ',')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_links(text):\n",
    "    if text[:3] == '###':\n",
    "        text = text[3:]\n",
    "\n",
    "    text = text.replace('###', ',')\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_product_info(text):\n",
    "    text = text.replace('###', ',')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "dataset_file = 'Metadata_excel.xlsx'\n",
    "df = pd.read_excel(dataset_file)\n",
    "\n",
    "# Fill NaN values with an empty string\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "columns_clean_special_chars = [\n",
    "    'schema', 'uuid', 'hierarchyLevel', 'title', 'abstract', 'keyword', 'geoBox', 'Constraints', \n",
    "    'SecurityConstraints', 'LegalConstraints', 'temporalExtent', 'responsibleParty',  \n",
    "    'productInformation', 'parentId'\n",
    "]\n",
    "# Apply cleaning functions columns\n",
    "for col in df.columns:\n",
    "    # Apply cleaning to all string columns\n",
    "    if df[col].dtype == 'object':\n",
    "        if col in columns_clean_special_chars:\n",
    "            df[col] = df[col].apply(clean_special_substrings)\n",
    "            #df[col] = df[col].apply(replace_norwegian_characters)\n",
    "\n",
    "        # Include cleaning of weird substrings\n",
    "        if col == 'abstract':\n",
    "            df[col] = df[col].apply(clean_abstract)\n",
    "        \n",
    "        # Clean keyword column\n",
    "        if col == 'keyword':\n",
    "            df[col] = df[col].apply(clean_hash_delimiter)\n",
    "\n",
    "        # Clean geoBox column\n",
    "        if col == 'geoBox':\n",
    "            df[col] = df[col].apply(clean_hash_delimiter)\n",
    "\n",
    "         # Clean Constraints column\n",
    "        if col == 'Constraints':\n",
    "            df[col] = df[col].apply(clean_constraints_column)\n",
    "       \n",
    "        # Clean SecurityConstraints column\n",
    "        if col == 'SecurityConstraints':\n",
    "            df[col] = df[col].apply(clean_security_constraints)\n",
    " \n",
    "        # Clean LegalConstraints column\n",
    "        if col == 'LegalConstraints':\n",
    "            df[col] = df[col].apply(clean_legal_constraints)\n",
    "        \n",
    "        # Clean LegalConstraints column\n",
    "        if col == 'responsibleParty':\n",
    "            df[col] = df[col].apply(clean_contact)\n",
    "\n",
    "        # Clean productInformation column\n",
    "        if col == 'productInformation':\n",
    "            df[col] = df[col].apply(clean_product_info)\n",
    "\n",
    "        # Clean links columns\n",
    "        if col in ['image', 'link']:\n",
    "            df[col] = df[col].apply(clean_links)\n",
    "\n",
    " \n",
    "cleaned_csv_file = 'output_metadata.csv'\n",
    "df.to_csv(cleaned_csv_file, sep='|', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load dataset and vectorise chosen columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from towhee import pipe, ops, DataCollection\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to compute embeddings for a single text\n",
    "def compute_embeddings(text):\n",
    "    MAX_TOKENS = 510 \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=MAX_TOKENS, truncation=True)\n",
    "    truncated_text = tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "\n",
    "    return DataCollection(embeddings_pipe(truncated_text)).to_list()[0]['vec'].tolist()\n",
    "\n",
    "\n",
    "# Loads dataset into dataframe and recasts columns into correct datatypes\n",
    "df_kartverket = pd.read_csv(cleaned_csv_file, sep='|')\n",
    "recast_to_string = ['datasetcreationdate', 'metadatacreationdate']\n",
    "df_kartverket[recast_to_string] = df_kartverket[recast_to_string].astype('object')\n",
    "\n",
    "# Fill NaN values with an empty string\n",
    "df_kartverket.fillna('', inplace=True)\n",
    "\n",
    "# Pipe converting text to embeddings (vectors) using a model\n",
    "facebook_context_model_name = 'facebook/dpr-ctx_encoder-single-nq-base'\n",
    "#facebook_question_model_name = 'facebook/dpr-question_encoder-single-nq-base'\n",
    "mbert_model_name = 'bert-base-multilingual-uncased'\n",
    "\n",
    "chosen_model = facebook_context_model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(chosen_model)\n",
    "embeddings_pipe = (\n",
    "    pipe.input('text')\n",
    "        .map('text', 'vec', ops.text_embedding.dpr(model_name=chosen_model))\n",
    "        .output('vec')\n",
    ")\n",
    "\n",
    "# Process each column and create new columns for embeddings\n",
    "columns_to_vectorise = ['title', 'abstract', 'keyword', 'geoBox', 'Constraints', 'SecurityConstraints', 'LegalConstraints', 'responsibleParty']\n",
    "\n",
    "for index, column in enumerate(columns_to_vectorise):\n",
    "    tqdm.pandas(desc=f\"Creating vector embeddings for '{column}' ({index + 1}/{len(columns_to_vectorise)})\")\n",
    "    df_kartverket[column + '_vector'] = df_kartverket[column].progress_apply(compute_embeddings)\n",
    "\n",
    "model_embedding_dimension = len(df_kartverket[columns_to_vectorise[0] + '_vector'][0])\n",
    "print(f\"dimensions of vectors: {model_embedding_dimension}\")\n",
    "\n",
    "df_kartverket.to_csv(chosen_model.replace('/', '-') + f'_{model_embedding_dimension}' + '.csv', index=False, sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
